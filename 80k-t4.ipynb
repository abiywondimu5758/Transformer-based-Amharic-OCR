{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gsutil --upgrade --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:47:51.284163Z","iopub.execute_input":"2025-06-26T11:47:51.284492Z","iopub.status.idle":"2025-06-26T11:47:54.469449Z","shell.execute_reply.started":"2025-06-26T11:47:51.284465Z","shell.execute_reply":"2025-06-26T11:47:54.468621Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree(\"/kaggle/working/trocr_frozen_head/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:47:55.230521Z","iopub.execute_input":"2025-06-26T11:47:55.230789Z","iopub.status.idle":"2025-06-26T11:47:55.299776Z","shell.execute_reply.started":"2025-06-26T11:47:55.230768Z","shell.execute_reply":"2025-06-26T11:47:55.298820Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1219/1549925104.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/trocr_frozen_head/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/trocr_frozen_head/'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/trocr_frozen_head/'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"!mkdir -p /kaggle/working/mydata\n## !rm -rf /kaggle/working/*\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:53:57.753241Z","iopub.execute_input":"2025-06-26T10:53:57.754007Z","iopub.status.idle":"2025-06-26T10:53:57.871481Z","shell.execute_reply.started":"2025-06-26T10:53:57.753969Z","shell.execute_reply":"2025-06-26T10:53:57.870444Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install -U transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:48:02.740083Z","iopub.execute_input":"2025-06-26T11:48:02.740425Z","iopub.status.idle":"2025-06-26T11:48:05.927448Z","shell.execute_reply.started":"2025-06-26T11:48:02.740396Z","shell.execute_reply":"2025-06-26T11:48:05.926632Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!gsutil -m cp -r gs://adoocr-data/train /kaggle/working/mydata/\n!gsutil -m cp -r gs://adoocr-data/test  /kaggle/working/mydata/ ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:54:16.630982Z","iopub.execute_input":"2025-06-26T10:54:16.631298Z","iopub.status.idle":"2025-06-26T10:58:20.186776Z","shell.execute_reply.started":"2025-06-26T10:54:16.631251Z","shell.execute_reply":"2025-06-26T10:58:20.186046Z"}},"outputs":[{"name":"stdout","text":"Copying gs://adoocr-data/train/X_trainp_pg_vg.npy...\nCopying gs://adoocr-data/train/mapping_labls...\nCopying gs://adoocr-data/train/y_trainp_pg_vg.npy...                            \nCopying gs://adoocr-data/test/X_test_vg.npy...84.1 MiB/s ETA 00:00:00           \nCopying gs://adoocr-data/test/mapping_labls...                                  \nCopying gs://adoocr-data/test/x_test_pg.npy...                                  \nCopying gs://adoocr-data/test/x_testp.npy...\nCopying gs://adoocr-data/test/y_test_pg.npy...                                  \nCopying gs://adoocr-data/test/y_test_vg.npy...                                  \nCopying gs://adoocr-data/test/y_testp.npy...\n| [7/8 files][877.9 MiB/877.9 MiB]  99% Done  68.1 MiB/s ETA 00:00:00           \r","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# %%bash\n# cat <<EOF > /kaggle/working/kaggle.json\n# {\"username\":\"abiywondimu\",\"key\":\"31fd71809a2ceeb88a6e435c42bfed37\"}\n# EOF\n\n# # secure the file\n# chmod 600 /kaggle/working/kaggle.json\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:21:45.410520Z","iopub.execute_input":"2025-06-26T10:21:45.410793Z","iopub.status.idle":"2025-06-26T10:21:45.427449Z","shell.execute_reply.started":"2025-06-26T10:21:45.410754Z","shell.execute_reply":"2025-06-26T10:21:45.426838Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# %%bash\n# mkdir -p ~/.kaggle\n# mv /kaggle/working/kaggle.json ~/.kaggle/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:21:45.428201Z","iopub.execute_input":"2025-06-26T10:21:45.428860Z","iopub.status.idle":"2025-06-26T10:21:45.444680Z","shell.execute_reply.started":"2025-06-26T10:21:45.428834Z","shell.execute_reply":"2025-06-26T10:21:45.444072Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# !cd /kaggle/working/mydata && kaggle datasets init","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:21:45.445582Z","iopub.execute_input":"2025-06-26T10:21:45.445924Z","iopub.status.idle":"2025-06-26T10:21:45.460118Z","shell.execute_reply.started":"2025-06-26T10:21:45.445899Z","shell.execute_reply":"2025-06-26T10:21:45.459546Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# !cd /kaggle/working/mydata\n# import json\n\n# meta_path = \"/kaggle/working/mydata/dataset-metadata.json\"\n# with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n#     data = json.load(f)\n\n# # >>> edit your fields:\n# data[\"title\"] = \"my amharic ocr lines\"\n# data[\"id\"]    = \"abiywondimu/amharic-textline-ocr\"\n# data[\"isPrivate\"] = True\n\n# with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n#     json.dump(data, f, ensure_ascii=False, indent=2)\n# print(\"Reâ€wrote metadata!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:21:45.460989Z","iopub.execute_input":"2025-06-26T10:21:45.461186Z","iopub.status.idle":"2025-06-26T10:21:45.477126Z","shell.execute_reply.started":"2025-06-26T10:21:45.461170Z","shell.execute_reply":"2025-06-26T10:21:45.476362Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# !cd /kaggle/working/mydata\n\n# !kaggle datasets create -p /kaggle/working/mydata --dir-mode tar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:21:45.479726Z","iopub.execute_input":"2025-06-26T10:21:45.480072Z","iopub.status.idle":"2025-06-26T10:21:45.496896Z","shell.execute_reply.started":"2025-06-26T10:21:45.480039Z","shell.execute_reply":"2025-06-26T10:21:45.496046Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# !kaggle config view","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:21:45.497690Z","iopub.execute_input":"2025-06-26T10:21:45.497948Z","iopub.status.idle":"2025-06-26T10:21:45.513019Z","shell.execute_reply.started":"2025-06-26T10:21:45.497920Z","shell.execute_reply":"2025-06-26T10:21:45.512260Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    VisionEncoderDecoderModel,\n    TrOCRProcessor,\n    TrainingArguments,\n    Trainer,\n    default_data_collator\n)\nimport editdistance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:48:12.626142Z","iopub.execute_input":"2025-06-26T11:48:12.626473Z","iopub.status.idle":"2025-06-26T11:48:31.925909Z","shell.execute_reply.started":"2025-06-26T11:48:12.626445Z","shell.execute_reply":"2025-06-26T11:48:31.925146Z"}},"outputs":[{"name":"stderr","text":"2025-06-26 11:48:24.496908: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750938504.705853    1219 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750938504.770134    1219 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"MODEL_NAME = \"microsoft/trocr-small-printed\"\nBATCH_SIZE = 32            \nEPOCHS     = 3\nLR         = 5e-5\nOUTPUT_DIR = \"./trocr_frozen_head\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:49:50.748244Z","iopub.execute_input":"2025-06-26T11:49:50.749037Z","iopub.status.idle":"2025-06-26T11:49:50.753475Z","shell.execute_reply.started":"2025-06-26T11:49:50.749008Z","shell.execute_reply":"2025-06-26T11:49:50.752721Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# â”€â”€â”€ 2) DATASET â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass LineOCRDataset(Dataset):\n    def __init__(self, images_np, labels_np, processor, idx2char, max_length=64):\n        self.X = images_np        # shape (N,48,128), dtype uint8 or float32\n        self.Y = labels_np        # shape (N, max_label_len), padded with 0\n        self.proc = processor\n        self.idx2char = idx2char\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, i):\n        img = self.X[i].astype(np.uint8)\n        # TrOCRProcessor expects PIL or np.array HÃ—WÃ—3, so stack channels:\n        img3 = np.stack([img, img, img], axis=-1)\n        pixel_values = self.proc(images=img3, return_tensors=\"pt\").pixel_values[0]\n\n        # decode Y[i] to string\n        seq = self.Y[i]\n        chars = []\n        for idx in seq:\n            if idx == 0: break  # pad\n            chars.append(self.idx2char[int(idx)])\n        text = \"\".join(chars)\n\n        labels = self.proc.tokenizer(\n            text, padding=\"max_length\", truncation=True,\n            max_length=self.max_length, return_tensors=\"pt\"\n        ).input_ids[0]\n\n        return {\n            \"pixel_values\": pixel_values,\n            \"labels\": labels,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:49:54.218433Z","iopub.execute_input":"2025-06-26T11:49:54.219093Z","iopub.status.idle":"2025-06-26T11:49:54.226020Z","shell.execute_reply.started":"2025-06-26T11:49:54.219056Z","shell.execute_reply":"2025-06-26T11:49:54.225147Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# â”€â”€â”€ 3) METRICS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef compute_metrics(pred):\n    pred_ids = pred.predictions.argmax(-1) if pred.predictions.ndim==3 else pred.predictions\n    pred_texts = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_ids  = pred.label_ids\n    label_ids[label_ids==-100] = processor.tokenizer.pad_token_id\n    gt_texts   = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    total_cer = total_wer = total_chars = total_words = correct_chars = 0\n    for p, g in zip(pred_texts, gt_texts):\n        # CER\n        total_cer  += editdistance.eval(p, g)\n        total_chars+= len(g)\n        # WER\n        pw = p.split(); gw = g.split()\n        total_wer  += editdistance.eval(pw, gw)\n        total_words+= len(gw)\n        # Char acc\n        for pc, gc in zip(p, g):\n            if pc==gc: correct_chars+=1\n\n    return {\n        \"cer\": total_cer/total_chars,\n        \"wer\": total_wer/total_words,\n        \"char_acc\": correct_chars/total_chars,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:49:58.972526Z","iopub.execute_input":"2025-06-26T11:49:58.973326Z","iopub.status.idle":"2025-06-26T11:49:58.979005Z","shell.execute_reply.started":"2025-06-26T11:49:58.973263Z","shell.execute_reply":"2025-06-26T11:49:58.978319Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# â”€â”€â”€ 4) LOAD DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# your .npy paths\nX_train = np.load(\"/kaggle/working/mydata/train/X_trainp_pg_vg.npy\", mmap_mode=\"r\")[:80000]\nY_train = np.load(\"/kaggle/working/mydata/train/y_trainp_pg_vg.npy\", allow_pickle=True)[:80000]\nX_val   = np.load(\"/kaggle/working/mydata/test/x_testp.npy\",  mmap_mode=\"r\")\nY_val   = np.load(\"/kaggle/working/mydata/test/y_testp.npy\",   allow_pickle=True)\n\n# build idx2char from your mapping file\nidx2char = {}\n\nspecial_tokens = {\n    \"<space>\": \" \",\n    \"<newline>\": \"\\n\",\n    \"<tab>\": \"\\t\"\n}\n\nwith open(\"/kaggle/working/mydata/train/mapping_labls\", encoding=\"utf-8\") as f:\n    for line in f:\n        parts = line.strip().split(maxsplit=1)\n        if len(parts) == 2:\n            i, ch = parts\n            ch = special_tokens.get(ch, ch)  # convert <space> etc to actual char\n            idx2char[int(i)] = ch\n\n\n\nprocessor = TrOCRProcessor.from_pretrained(MODEL_NAME)\n\ntrain_ds = LineOCRDataset(X_train, Y_train, processor, idx2char)\nval_ds   = LineOCRDataset(X_val,   Y_val,   processor, idx2char)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:50:19.823514Z","iopub.execute_input":"2025-06-26T11:50:19.823837Z","iopub.status.idle":"2025-06-26T11:50:21.883506Z","shell.execute_reply.started":"2025-06-26T11:50:19.823813Z","shell.execute_reply":"2025-06-26T11:50:21.882833Z"}},"outputs":[{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# print(\"Sample label indices:\", dataset[0][\"label_ids\"])\n\nprint(\"Available label indices:\", sorted(idx2char.keys()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:50:25.231555Z","iopub.execute_input":"2025-06-26T11:50:25.232156Z","iopub.status.idle":"2025-06-26T11:50:25.236242Z","shell.execute_reply.started":"2025-06-26T11:50:25.232135Z","shell.execute_reply":"2025-06-26T11:50:25.235575Z"}},"outputs":[{"name":"stdout","text":"Available label indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# â”€â”€â”€ 5) MODEL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmodel = VisionEncoderDecoderModel.from_pretrained(MODEL_NAME)\n\n# freeze entire encoder\nfor param in model.encoder.parameters():\n    param.requires_grad = False\n\n# set pad token\nmodel.config.decoder_start_token_id = processor.tokenizer.cls_token_id\nmodel.config.pad_token_id           = processor.tokenizer.pad_token_id\nmodel.config.vocab_size             = model.config.decoder.vocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:50:29.038620Z","iopub.execute_input":"2025-06-26T11:50:29.039200Z","iopub.status.idle":"2025-06-26T11:50:32.615118Z","shell.execute_reply.started":"2025-06-26T11:50:29.039176Z","shell.execute_reply":"2025-06-26T11:50:32.614329Z"}},"outputs":[{"name":"stderr","text":"Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from transformers import EarlyStoppingCallback\n\n# â”€â”€â”€ 6) TRAINER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    per_device_train_batch_size=BATCH_SIZE,\n    save_total_limit=2,\n    fp16=True,\n    learning_rate=LR,\n    logging_steps=200,\n    report_to=\"none\",\n    save_strategy=\"no\",  # no save if you're not evaluating\n    eval_strategy=\"no\"  # disable eval\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    # eval_dataset=val_ds,  # <-- comment or remove this line\n    data_collator=default_data_collator,\n    compute_metrics=None,\n    callbacks=[]\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:50:51.976686Z","iopub.execute_input":"2025-06-26T11:50:51.977442Z","iopub.status.idle":"2025-06-26T11:50:53.054305Z","shell.execute_reply.started":"2025-06-26T11:50:51.977415Z","shell.execute_reply":"2025-06-26T11:50:53.053708Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# â”€â”€â”€ 7) TRAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:50:56.932529Z","iopub.execute_input":"2025-06-26T11:50:56.933185Z","iopub.status.idle":"2025-06-26T12:57:19.813208Z","shell.execute_reply.started":"2025-06-26T11:50:56.933160Z","shell.execute_reply":"2025-06-26T12:57:19.812430Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3750/3750 1:06:18, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>0.643400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.380900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.372700</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.366100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.363200</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.362000</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.359800</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.356700</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.354000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.352600</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.351600</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.350500</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.348200</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.348000</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.345500</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.345300</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.343600</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.343800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3750, training_loss=0.3704139149983724, metrics={'train_runtime': 3982.4452, 'train_samples_per_second': 60.264, 'train_steps_per_second': 0.942, 'total_flos': 2.870992498065408e+19, 'train_loss': 0.3704139149983724, 'epoch': 3.0})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# â”€â”€â”€ 8) SAVE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntrainer.save_model(OUTPUT_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T12:58:51.037820Z","iopub.execute_input":"2025-06-26T12:58:51.038206Z","iopub.status.idle":"2025-06-26T12:58:51.597396Z","shell.execute_reply.started":"2025-06-26T12:58:51.038179Z","shell.execute_reply":"2025-06-26T12:58:51.596766Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"!zip -r /kaggle/working/trocr_frozen_head.zip /kaggle/working/trocr_frozen_head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:03:10.603126Z","iopub.execute_input":"2025-06-26T13:03:10.604091Z","iopub.status.idle":"2025-06-26T13:03:51.571600Z","shell.execute_reply.started":"2025-06-26T13:03:10.604053Z","shell.execute_reply":"2025-06-26T13:03:51.570833Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/trocr_frozen_head/ (stored 0%)\n  adding: kaggle/working/trocr_frozen_head/training_args.bin (deflated 52%)\n  adding: kaggle/working/trocr_frozen_head/config.json (deflated 65%)\n  adding: kaggle/working/trocr_frozen_head/model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 28%)\n  adding: kaggle/working/trocr_frozen_head/generation_config.json (deflated 35%)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!pip install -q google-cloud-storage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:11:41.252719Z","iopub.execute_input":"2025-06-26T13:11:41.253430Z","iopub.status.idle":"2025-06-26T13:11:55.101477Z","shell.execute_reply.started":"2025-06-26T13:11:41.253403Z","shell.execute_reply":"2025-06-26T13:11:55.100708Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.25.1 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!gsutil -m cp -r gs://adoocr-data/train/service-account-key.json /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:18:53.096674Z","iopub.execute_input":"2025-06-26T13:18:53.097054Z","iopub.status.idle":"2025-06-26T13:18:54.560464Z","shell.execute_reply.started":"2025-06-26T13:18:53.097023Z","shell.execute_reply":"2025-06-26T13:18:54.559487Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Copying gs://adoocr-data/train/service-account-key.json...\n/ [1/1 files][  2.3 KiB/  2.3 KiB] 100% Done                                    \nOperation completed over 1 objects/2.3 KiB.                                      \n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from google.cloud import storage\nimport os\n\n# Path to service account key\nkey_path = \"/kaggle/working/service-account-key.json\"\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_path\n\n# Initialize GCS client\nclient = storage.Client()\nbucket_name = 'adoocr-data'  # TODO: Replace this with your actual bucket name\ndestination_blob_name = 'trocr_frozen_head.zip'\nsource_file_name = '/kaggle/working/trocr_frozen_head.zip'\n\n# Upload file\nbucket = client.get_bucket(bucket_name)\nblob = bucket.blob(destination_blob_name)\nblob.upload_from_filename(source_file_name)\n\nprint(\"âœ… Upload to GCP completed!\")\nprint(f\"ğŸ”— File URL: https://storage.googleapis.com/{bucket_name}/{destination_blob_name}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:25:30.921734Z","iopub.execute_input":"2025-06-26T13:25:30.922539Z","iopub.status.idle":"2025-06-26T13:25:32.843092Z","shell.execute_reply.started":"2025-06-26T13:25:30.922509Z","shell.execute_reply":"2025-06-26T13:25:32.842356Z"}},"outputs":[{"name":"stdout","text":"âœ… Upload to GCP completed!\nğŸ”— File URL: https://storage.googleapis.com/adoocr-data/trocr_frozen_head.zip\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"for blob in bucket.list_blobs():\n    print(blob.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:23:02.822157Z","iopub.execute_input":"2025-06-26T13:23:02.822801Z","iopub.status.idle":"2025-06-26T13:23:02.849331Z","shell.execute_reply.started":"2025-06-26T13:23:02.822774Z","shell.execute_reply":"2025-06-26T13:23:02.848497Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1219/4200985662.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'bucket' is not defined"],"ename":"NameError","evalue":"name 'bucket' is not defined","output_type":"error"}],"execution_count":33}]}